{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d963651-1d8b-4c83-a025-3870c2cd8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate\n",
    "import scipy.signal\n",
    "import PIL.Image\n",
    "\n",
    "from ntsc import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "237b0bd8-2fe4-431a-91d0-6097ce4344d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Signal:\n",
    "    def __init__(self, input_filename):\n",
    "        with np.load(\"./tv-signal.npz\") as f:\n",
    "            self.sample_rate = f[\"sample_rate\"]\n",
    "            self._signal = f[\"signal\"]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self._generate())\n",
    "    \n",
    "    def _generate(self):\n",
    "        # Each block is ~100µs of samples\n",
    "        block_ptr = 0\n",
    "        block_len = int(math.ceil(100 * self.sample_rate))\n",
    "        while block_ptr < self._signal.shape[0]:\n",
    "            yield self._signal[block_ptr:block_ptr+block_len, ...]\n",
    "            block_ptr += block_len\n",
    "            \n",
    "            \n",
    "def blocks_filtered_by(blocks, filter_, *, sample_rate):\n",
    "    buffer_size = int(math.ceil(100 * sample_rate)) # ~ 100µs\n",
    "    prior_block = np.zeros((buffer_size, ))\n",
    "    for block in blocks:\n",
    "        # Prepend prior block to avoid discontinuities around blocks\n",
    "        filtered_signal = filter_(np.concatenate((prior_block, block)))\n",
    "        yield filtered_signal[prior_block.shape[0]:]\n",
    "        prior_block = filtered_signal[-buffer_size:]\n",
    "\n",
    "def channel_filter(blocks, sample_rate, *, bandwidth=6):\n",
    "    # Simulate a bandwidth limit with a Butterworth low-pass filter.\n",
    "    sos = scipy.signal.butter(5, bandwidth, analog=False, btype=\"low\", fs=sample_rate, output=\"sos\")\n",
    "    for b in blocks_filtered_by(blocks, lambda s: scipy.signal.sosfilt(sos, s), sample_rate=sample_rate):\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40c61cf1-13ef-406b-83de-a00c56956404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_sync(block):\n",
    "    \"Recover a composite sync signal for a block by thresholding\"\n",
    "    # Implement sync separator from https://www.ntsc-tv.com/images/tv/sync-sp.gif\n",
    "    clip_level = -25\n",
    "    return np.where(block >= clip_level, 1.0, 0.0)\n",
    "\n",
    "\n",
    "def recover_vsync(cs, sample_rate):\n",
    "    # We restore the vertical sync by low-pass filtering the composite sync.\n",
    "    # We need a -3dB frequency which is above the line frequency (so we\n",
    "    # retrive the vsync pulse) but which is well below the frequency implied by\n",
    "    # the hsync pulse length.\n",
    "\n",
    "    # The frequency implied by the h-sync pulse. (I.e. a period of two\n",
    "    # times the pulse width.)\n",
    "    h_sync_implied_frequency = 1 / (2 * H_SYNC_DURATION)\n",
    "\n",
    "    # Choose a cutoff frequency well below the implied pulse frequence.\n",
    "    cutoff_frequency = 0.1 * h_sync_implied_frequency\n",
    "\n",
    "    # A simple first order Butterworth filter. Some TVs just use an passive RC filter for this\n",
    "    # and so we don't need to be too clever.\n",
    "    sos = scipy.signal.butter(1, cutoff_frequency, analog=False, btype=\"low\", fs=sample_rate, output=\"sos\")\n",
    "    lowpass_signal = scipy.signal.sosfilt(sos, cs)\n",
    "    return lowpass_signal\n",
    "\n",
    "    # Compute VSync via comparator.\n",
    "    return np.where(lowpass_signal < 0.66, 0, 1)\n",
    "\n",
    "\n",
    "def fields(blocks, *, sample_rate):\n",
    "    \"Yield pairs giving snipped region from vsync to vsync and the recovered hsync for the region.\"\n",
    "    # Build up a buffer of blocks. When we find a start end end vsync pulse in the\n",
    "    # buffer we yield a section of the buffer as a field between the pulses.\n",
    "    block_buffer = collections.deque()\n",
    "    block_buffer_len = 0\n",
    "    \n",
    "    # Minimum number of samples in the buffer to attempt field detection. A full\n",
    "    # frame should contain two vsync pulses and so we buffer just over one frame.\n",
    "    min_buffer_len = int(math.ceil(FRAME_TOTAL_LINES * LINE_DURATION * sample_rate * 1.2))\n",
    "    \n",
    "    for block in blocks:\n",
    "        block_buffer.append(block)\n",
    "        block_buffer_len += block.shape[0]\n",
    "        if block_buffer_len < min_buffer_len:\n",
    "            continue\n",
    "            \n",
    "        # We have a buffer we expect to contain at least two vsyncs. Snip it out\n",
    "        buffer_samples = np.concatenate(block_buffer)\n",
    "        \n",
    "        # Get composite sync\n",
    "        cs = composite_sync(buffer_samples)\n",
    "        \n",
    "        # Low-pass filter and threshold to recover vsync\n",
    "        vs = recover_vsync(cs, sample_rate)\n",
    "        \n",
    "        # Find vsync -ve going edges in the buffer.\n",
    "        vsync_edges = (np.logical_and(vs[:-1] > 0.5, vs[1:] < 0.5)).nonzero()[0]\n",
    "        \n",
    "        # Ignore edges within 1 line delay to account for lag in lowpass filter.\n",
    "        vsync_edges = vsync_edges[vsync_edges > LINE_DURATION * sample_rate]\n",
    "        \n",
    "        # There must be at least one edge\n",
    "        if vsync_edges.shape[0] < 1:\n",
    "            continue\n",
    "            \n",
    "        # Now find the next edge which should be at least one half field in the future\n",
    "        vsync_start = vsync_edges[0]\n",
    "        vsync_edges = vsync_edges[vsync_edges > vsync_start + 0.25 * FRAME_TOTAL_LINES * LINE_DURATION * sample_rate]\n",
    "                                  \n",
    "        # We expect at least one other edge. Otherwise, snip at the one we have and continue\n",
    "        if vsync_edges.shape[0] < 1:\n",
    "            block_buffer = [buffer_samples[vsync_start:]]\n",
    "            block_buffer_len = block_buffer[0].shape[0]\n",
    "            continue\n",
    "            \n",
    "        vsync_end = vsync_edges[0]\n",
    "            \n",
    "        # Put region of buffer around a line and a half before second edge back\n",
    "        # in block buffer\n",
    "        block_buffer = [\n",
    "            buffer_samples[max(0, vsync_end - int(math.ceil(LINE_DURATION * 1.5 * sample_rate))):]\n",
    "        ]\n",
    "        block_buffer_len = block_buffer[0].shape[0]\n",
    "        \n",
    "        # Yield snipped region\n",
    "        yield buffer_samples[vsync_start:vsync_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4e13549-5d06-49b8-9d8f-71c947711acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_field(field_time, field, sample_rate):  \n",
    "    # The horizontal sync is recovered by triggering on low-going pulses from the\n",
    "    # composite sync but not re-triggering for some hold time. (In the sync separator\n",
    "    # circuit this is done by having the reset line for the one-shot trigger driven\n",
    "    # by an RC-filter.) Implementing this efficiently in numpy is a little tricky.\n",
    "\n",
    "    # Compute indices of low-going edges from composite sync.\n",
    "    cs = composite_sync(field)\n",
    "    cs_low_going_edge_indices = np.logical_and(cs[:-1] > 0.5, cs[1:] <= 0.5).nonzero()[0]\n",
    "\n",
    "    # Now many samples in the future must the next low-going edge be? We make this\n",
    "    # most of a line.\n",
    "    min_sample_separation = 0.8 * LINE_DURATION * sample_rate\n",
    "\n",
    "    # Recovered hsync edges\n",
    "    h_sync_edges = []\n",
    "\n",
    "    # Walk edges adding in sync pulses.\n",
    "    for edge_idx in cs_low_going_edge_indices:\n",
    "        if len(h_sync_edges) == 0 or (edge_idx - h_sync_edges[-1]) >= min_sample_separation:\n",
    "            h_sync_edges.append(edge_idx)\n",
    "    \n",
    "    # Reject first 18 edges to allow hsync to have actually synchronised and stopped\n",
    "    # being confused by vsync. This should line us up with the start of the active area.\n",
    "    h_sync_edges = h_sync_edges[18:]\n",
    "    \n",
    "    # We must have enough for the actual field\n",
    "    assert len(h_sync_edges) > FRAME_ACTIVE_LINES >> 1\n",
    "    \n",
    "    # What is the fractional difference between hsync and vsync location measured in\n",
    "    # line delays?\n",
    "    hv_drift = np.fmod(h_sync_edges[0] / (LINE_DURATION * sample_rate), 1.0)\n",
    "    \n",
    "    # Use this to detect even vs odd fields\n",
    "    is_even = hv_drift > 0.5\n",
    "\n",
    "    # Expected samples per line\n",
    "    samples_per_line = int(math.ceil(LINE_DURATION * signal.sample_rate))\n",
    "    \n",
    "    # Decode lines\n",
    "    line_time = field_time\n",
    "    decoded_lines = np.zeros((FRAME_ACTIVE_LINES>>1, FRAME_H_PIXELS, 3))\n",
    "    for line_idx, (start_idx, end_idx) in enumerate(zip(h_sync_edges[:FRAME_ACTIVE_LINES>>1], h_sync_edges[1:])):\n",
    "        line_samples = field[start_idx:end_idx]\n",
    "        decoded_lines[line_idx, ...] = decode_line(line_idx, field_time + start_idx / sample_rate, line_samples, sample_rate)\n",
    "\n",
    "    return is_even, decoded_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85c3c39d-8ba0-4a45-a8ef-78d784f84e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_colourburst_phase(cb_freq, cb_times, cb_samples):\n",
    "    complex_cb = COLOUR_CARRIER_AMPLITUDE * np.exp(1j * cb_freq * 2 * np.pi * cb_times)\n",
    "    response = np.sum(cb_samples * complex_cb)\n",
    "    cb_phase = -np.angle(response)\n",
    "    return cb_phase\n",
    "\n",
    "def decode_line(line_idx, line_time, line, sample_rate):\n",
    "    # Times within line of each sample.\n",
    "    line_times = line_time + np.arange(line.shape[0]) / sample_rate\n",
    "\n",
    "    # Prepare buffer for line luma and I/Q components\n",
    "    line_yiq = np.zeros((line.shape[0], 3))\n",
    "    \n",
    "    # Compute chroma bandpass filter based on the nominal colour burst frequency.\n",
    "    bp_quality = 1\n",
    "    colourbust_bp_ba = scipy.signal.iirpeak(COLOUR_CARRIER_FREQUENCY, bp_quality, sample_rate)\n",
    "    \n",
    "    # Filter line into luma and chroma components\n",
    "    chroma = scipy.signal.lfilter(*colourbust_bp_ba, x=line)\n",
    "    line_yiq[..., 0] = (line - chroma - BLACK_LEVEL) / (WHITE_LEVEL - BLACK_LEVEL)\n",
    "\n",
    "    # Extract colour burst from chroma bandpass filtered signal\n",
    "    cb_start_sample = int(math.floor(COLOUR_BURST_START_TIME * sample_rate))\n",
    "    cb_sample_count = int(math.ceil(COLOUR_BURST_START_TIME * sample_rate))\n",
    "    cb_samples = chroma[cb_start_sample:cb_start_sample+cb_sample_count]\n",
    "    cb_times = line_times[cb_start_sample:cb_start_sample+cb_sample_count]\n",
    "\n",
    "    # For the moment we do not attempt to track colourbust frequency.\n",
    "    cb_phase = reconstruct_colourburst_phase(COLOUR_CARRIER_FREQUENCY, cb_times, cb_samples)\n",
    "\n",
    "    # Demodulate I and Q components.\n",
    "    cb_subcarrier = np.exp(1j * (COLOUR_CARRIER_FREQUENCY * 2 * np.pi * line_times + cb_phase))\n",
    "    line_yiq[..., 1] = np.real(cb_subcarrier) * chroma / COLOUR_CARRIER_AMPLITUDE\n",
    "    line_yiq[..., 2] = np.imag(cb_subcarrier) * chroma / COLOUR_CARRIER_AMPLITUDE\n",
    "\n",
    "    # Pass demodulation through lowpass filter using nominal chroma burst frequency.\n",
    "    colourburst_low_sos = scipy.signal.butter(\n",
    "        2, 0.5 * COLOUR_CARRIER_FREQUENCY,\n",
    "        analog=False, btype=\"lowpass\", fs=sample_rate, output=\"sos\"\n",
    "    )\n",
    "    line_yiq[..., 1:] = scipy.signal.sosfilt(colourburst_low_sos, line_yiq[..., 1:], axis=0)\n",
    "    \n",
    "    # Convert YIQ to RGB\n",
    "    line_rgb = np.zeros_like(line_yiq)\n",
    "    line_rgb[..., 0] = line_yiq[..., 1] + line_yiq[..., 0]\n",
    "    line_rgb[..., 2] = line_yiq[..., 2] + line_yiq[..., 0]\n",
    "    line_rgb[..., 1] = (line_yiq[..., 0] - 0.3 * line_rgb[..., 0] - 0.11 * line_rgb[..., 2]) / 0.59\n",
    "\n",
    "    # Resample line into pixels\n",
    "    line_interpolator = scipy.interpolate.interp1d(x=line_times, y=line_rgb, axis=0, kind=\"quadratic\")\n",
    "    pixel_duration = ACTIVE_DURATION / FRAME_H_PIXELS\n",
    "    pixel_times = line_time + np.arange(FRAME_H_PIXELS) * pixel_duration + H_SYNC_DURATION + BACK_PORCH_DURATION\n",
    "    return np.clip(line_interpolator(pixel_times), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29d402-88cd-4271-8463-58b424a51595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input signal sampled at 35.77MHz\n",
      "Detected field at 0.000ms of duration 16.695ms\n",
      "Detected field at 16.695ms of duration 16.695ms\n",
      "Detected field at 33.390ms of duration 16.695ms\n",
      "Detected field at 50.085ms of duration 16.695ms\n"
     ]
    }
   ],
   "source": [
    "signal = Signal(\"./tv-signal.npz\")\n",
    "print(f\"Input signal sampled at {signal.sample_rate:.2f}MHz\")\n",
    "\n",
    "received_signal_blocks = channel_filter(signal, sample_rate=signal.sample_rate)\n",
    "\n",
    "# Approximate number of samples per field\n",
    "expected_field_sample_count = 0.5 * FRAME_TOTAL_LINES * LINE_DURATION * signal.sample_rate\n",
    "\n",
    "frame_image = 0.5 * np.ones((FRAME_ACTIVE_LINES, FRAME_H_PIXELS, 3))\n",
    "field_time = 0  # µs\n",
    "for field_idx, field in enumerate(fields(received_signal_blocks, sample_rate=signal.sample_rate)):\n",
    "    print(f\"Detected field at {field_time*1e-3:.3f}ms of duration {1e-3 * field.shape[0] / signal.sample_rate:.3f}ms\")\n",
    "    \n",
    "    # Reject field which is too short\n",
    "    if field.shape[0] < 0.9 * expected_field_sample_count:\n",
    "        print(\"Rejecting field which is too short\")\n",
    "        continue\n",
    "        \n",
    "    is_even, field_image = decode_field(field_time, field, signal.sample_rate)\n",
    "    if is_even:\n",
    "        frame_image[1::2, ...] = field_image\n",
    "    else:\n",
    "        frame_image[0::2, ...] = field_image\n",
    "        \n",
    "    # Give decode a chance to settle before saving frames\n",
    "    if field_idx > 3:\n",
    "        PIL.Image.fromarray((255 * frame_image).astype(np.uint8)).save(\n",
    "            f\"decoded-{field_idx-3:04d}.png\"\n",
    "        )\n",
    "\n",
    "    field_time += field.shape[0] / signal.sample_rate\n",
    "    \n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(frame_image)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb9b50-67b4-42bb-8a14-6579a96bd7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
